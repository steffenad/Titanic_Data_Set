# Exploring Titanic Data Set

# Goal: Practicing Data Preparation, Exploration and Classification Modeling Processes



### Loading Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline


### Loading Data Set (Titanic Data Set from Kaggle: https://www.kaggle.com/c/titanic)

train = pd.read_excel('Titanic_Train.xlsx')
test = pd.read_excel('Titanic_Test.xlsx')


### Data Preparation

# convert data type to 'category' for PassengerId, Pclass, Ticket, Name and Embarked
train[['Survived','PassengerId','Pclass','Ticket','Name','Embarked']] = train[['Survived','PassengerId','Pclass','Ticket','Name','Embarked']].astype('category')


# delete irrelevant features: PassengerId and Ticket redundant, Cabin too many missing values
train.drop(['PassengerId','Cabin','Ticket'],axis=1, inplace=True)


# Missing values


# Any missing values?
train.isnull().values.any()

# Total missing values for each feature
train.isnull().sum()

#plotting missing values
sns.heatmap(train.isnull(),yticklabels=False,cbar=False)

#observations with missing values for variable "Fare"
train[train['Fare'].isnull()]

# deleting one observation with missing value for "Fare"
train.drop([152],inplace=True)

# imputing mean for missing values in "Age"
train['Age'] = train['Age'].fillna(value=train['Age'].mean())

#plotting missing values now
sns.heatmap(train.isnull(),yticklabels=False,cbar=False)


#change names for feature "Survived"
def change(parameter):
    if parameter == 1:
        return 'Survived'
    else:
        return 'Died'
train['Survived']= list(map(change,train['Survived']))

#function: include 'children' into gender column

def person (age, gender):
    if age < 18:
        return 'child'
    else:
        return gender
        
train['Person'] = list(map(person,train['Age'],train['Sex']))
train = train.drop('Sex',axis=1)


### Data Exploration and Visualisation


#Survivals

#plotting Survivals
sns.countplot(x="Survived",data=train)

#How many male, female passengers and childen were on board?
sns.countplot(x="Person",data=train)

#How many males, females and children were in different ship classes?
sns.countplot(x="Person",hue="Pclass",data=train)

#plotting Survivals and Class
sns.countplot(x='Survived',data=train, hue='Pclass')

#plotting Survivals separated in 2 two grids for different passenger classes
sns.catplot(x='Pclass',data=train,hue='Person',col='Survived',kind='count')


#age of passengers and its distribution per class
sns.boxplot(x='Pclass',y='Age',data=train)


#distribution for 'Age' and 'Fare'
train['Fare'].hist(grid=False)
train['Age'].hist(grid=False)

Data Preparation


#dummify categorical variables for classification models

sex = pd.get_dummies(train['Person'],drop_first=True)
embarked = pd.get_dummies(train['Embarked'],drop_first=True)

#drop features replaced by dummys and combine new features with train data set
train.drop(['Person','Embarked'],axis=1,inplace=True)
train = pd.concat([train,sex,embarked],axis=1)


Modelling Process

#Separating Data Set into training and testing data
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived',axis=1), 
                                                    train['Survived'], test_size=0.30, 
                                                    random_state=101)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.model_selection import GridSearchCV

#first Classification model tested
model = RandomForestClassifier()

#gridsearch for finding best parameter (number of trees)

def RF_param_selection(X, y, nfolds):
    trees = [300,390,400,420,430,440,450,460,500]
    
    param_grid = {'n_estimators': trees}
    grid_search = GridSearchCV(model, param_grid, cv=nfolds)
    grid_search.fit(X, y)
    grid_search.best_params_
    return grid_search.best_params_
    
    
  RF_param_selection(X_train,y_train, 5)
  
  #best parameter found (430 trees)
  
  model = RandomForestClassifier(n_estimators= 430)
  
  #train the model
  
  model.fit(X_train,y_train)
  
  #making predictions
  
  predictions = model.predict(X_test)
  
  
  #evaluate model
  
  print(confusion_matrix(y_test,predictions))
  
  print(classification_report(y_test,predictions))
  
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import accuracy_score

print('Accuracy: ',accuracy_score(y_test,predictions))
print('Kappa:    ', cohen_kappa_score(predictions,y_test))
  
  
  
  
